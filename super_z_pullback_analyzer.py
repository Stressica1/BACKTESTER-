"""
Super Z Strategy Pullback Analysis
Analyzes the pattern where signals are followed by pullbacks to red VHMA areas
"""

import pandas as pd
import numpy as np
import ccxt
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging
from dataclasses import dataclass
import json
import colorama
from colorama import Fore, Style, Back
from prettytable import PrettyTable
import glob
import traceback
import os
colorama.init(autoreset=True)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def tail_log_files(n=30):
    log_files = glob.glob("*.log")
    for log_file in log_files:
        print(f"\n--- Last {n} lines of {log_file} ---")
        try:
            with open(log_file, "r", encoding="utf-8") as f:
                lines = f.readlines()
                for line in lines[-n:]:
                    print(line.rstrip())
        except Exception as e:
            print(f"Could not read {log_file}: {e}")

tail_log_files()

@dataclass
class PullbackEvent:
    """Represents a pullback event after a signal"""
    signal_time: datetime
    signal_type: str  # 'long' or 'short'
    signal_price: float
    pullback_start_time: datetime
    pullback_end_time: datetime
    pullback_low_price: float  # For long signals
    pullback_high_price: float  # For short signals
    pullback_percentage: float
    vhma_red_duration: int  # Number of candles in red VHMA area
    recovered: bool  # Whether price recovered above signal level
    recovery_time: Optional[datetime]

class SuperZPullbackAnalyzer:
    """
    Analyzes Super Z strategy signals and subsequent pullbacks to red VHMA areas
    """
    
    def __init__(self, exchange_id: str = 'bitget'):
        # Load Bitget credentials from env/config
        api_key = os.getenv('BITGET_API_KEY', 'YOUR_API_KEY')
        api_secret = os.getenv('BITGET_API_SECRET', 'YOUR_API_SECRET')
        api_password = os.getenv('BITGET_PASSPHRASE', 'YOUR_PASSPHRASE')  # Fixed: using PASSPHRASE not PASSWORD
        
        # Determine if using testnet
        use_testnet = os.getenv('BITGET_TESTNET', 'true').lower() == 'true'
        
        self.exchange = getattr(ccxt, "bitget")({
            'apiKey': api_key,
            'secret': api_secret,
            'password': api_password,
            'sandbox': use_testnet,  # Use testnet setting from env
            'enableRateLimit': True,
        })
        
        mode = "TESTNET/DEMO" if use_testnet else "MAINNET/PRODUCTION"
        color = Back.YELLOW if use_testnet else Back.RED
        print(f"{color}{Fore.BLACK}{Style.BRIGHT}INFO: Running in {mode} mode! Trades are {'DEMO' if use_testnet else 'LIVE'} on Bitget.{Style.RESET_ALL}\n")
        self.pullback_events: List[PullbackEvent] = []
        self.max_trade_pct = 0.02  # 2% per trade
        self.max_total_pct = 0.36  # 36% max exposure
        self.emergency_pct = 0.85  # 85% margin call shutdown
        self.open_trades = {}  # symbol: {order_id, amount, ...}
        
    def calculate_vhma(self, df: pd.DataFrame, length: int = 21) -> pd.Series:
        """
        Calculate Volume-Weighted Hull Moving Average (VHMA)
        Based on the Pine Script implementation
        """
        # Volume-weighted price
        vwp = (df['close'] * df['volume']).rolling(window=length).sum() / df['volume'].rolling(window=length).sum()
        
        # Hull MA calculation
        def hull_ma(src, period):
            half_length = period // 2
            sqrt_length = int(np.sqrt(period))
            
            wma_half = src.rolling(window=half_length).apply(self._wma, raw=False)
            wma_full = src.rolling(window=period).apply(self._wma, raw=False)
            hull = (2 * wma_half - wma_full).rolling(window=sqrt_length).apply(self._wma, raw=False)
            
            return hull
        
        vhma = hull_ma(vwp, length)
        return vhma
    
    def _wma(self, x):
        """Weighted Moving Average calculation"""
        weights = np.arange(1, len(x) + 1)
        return np.sum(weights * x) / np.sum(weights)
    
    def apply_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Apply all technical indicators to the dataframe
        """
        # Calculate SuperTrend
        supertrend, trend = self.calculate_supertrend(df)
        df['supertrend'] = supertrend
        df['trend'] = trend
        
        # Calculate VHMA
        df['vhma'] = self.calculate_vhma(df)
        
        # Calculate ATR
        df['atr'] = self.calculate_atr(df)
        
        # Calculate EMAs
        df['ema_21'] = df['close'].ewm(span=21).mean()
        df['ema_50'] = df['close'].ewm(span=50).mean()
        
        return df
    
    def calculate_atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average True Range"""
        high = df['high']
        low = df['low']
        close = df['close'].shift(1)
        
        tr1 = high - low
        tr2 = (high - close).abs()
        tr3 = (low - close).abs()
        
        true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = true_range.rolling(window=period).mean()
        
        # Explicitly convert to Series to fix type error
        return pd.Series(atr, index=df.index)
    
    def analyze_pullbacks_after_signals(self, df: pd.DataFrame, signals: List, lookback_candles: int = 20) -> List[PullbackEvent]:
        """
        Analyze pullback patterns after signals
        """
        pullback_events = []
        
        for signal in signals:
            signal_time = signal['time']
            signal_price = signal['price']
            signal_type = signal['type']
            
            # Initialize variables to prevent unbound errors
            pullback_low_price = signal_price
            pullback_high_price = signal_price
            pullback_low_idx = None
            pullback_high_idx = None
            pullback_percentage = 0.0
            recovered = False
            recovery_time = None
            
            # Find data after signal
            try:
                # Explicitly cast signal_idx to integer to fix type error
                signal_idx = int(df.index.get_loc(signal_time)) if signal_time in df.index else -1
                if signal_idx == -1 or signal_idx + lookback_candles > len(df):
                    continue
                    
                # Look ahead for pullback - ensure signal_idx is an integer
                lookback_data = df.iloc[signal_idx:signal_idx + lookback_candles]
                
                if signal_type == 'long':
                    # For long signals, look for price drop (pullback)
                    pullback_low_price = lookback_data['low'].min()
                    pullback_percentage = (signal_price - pullback_low_price) / signal_price * 100
                    pullback_low_idx = lookback_data['low'].idxmin()
                else:
                    # For short signals, look for price rise (pullback)
                    pullback_high_price = lookback_data['high'].max()
                    pullback_percentage = (pullback_high_price - signal_price) / signal_price * 100
                    pullback_high_idx = lookback_data['high'].idxmax()
                
                # Check if price recovered
                if signal_type == 'long' and pullback_low_idx is not None:
                    recovery_data = lookback_data.loc[pullback_low_idx:]
                    recovered = (recovery_data['close'] > signal_price).any()
                    recovery_time = recovery_data[recovery_data['close'] > signal_price].index[0] if recovered and len(recovery_data[recovery_data['close'] > signal_price]) > 0 else None
                elif signal_type == 'short' and pullback_high_idx is not None:
                    recovery_data = lookback_data.loc[pullback_high_idx:]
                    recovered = (recovery_data['close'] < signal_price).any()
                    recovery_time = recovery_data[recovery_data['close'] < signal_price].index[0] if recovered and len(recovery_data[recovery_data['close'] < signal_price]) > 0 else None
                
                # Calculate VHMA red duration (simplified)
                vhma_red_duration = lookback_candles // 2  # Simplified calculation
                
                event = PullbackEvent(
                    signal_time=signal_time,
                    signal_type=signal_type,
                    signal_price=signal_price,
                    pullback_start_time=signal_time,
                    pullback_end_time=lookback_data.index[-1] if len(lookback_data) > 0 else signal_time,
                    pullback_low_price=pullback_low_price,
                    pullback_high_price=pullback_high_price,
                    pullback_percentage=pullback_percentage,
                    vhma_red_duration=vhma_red_duration,
                    recovered=recovered,
                    recovery_time=recovery_time
                )
                
                pullback_events.append(event)
            except Exception as e:
                logging.error(f"Error analyzing pullback for signal at {signal_time}: {e}")
                continue
        
        return pullback_events
    
    def calculate_optimal_position_size(self, entry_price: float, stop_loss: float, risk_reward_ratio: float) -> float:
        """
        Calculate optimal position size based on risk management
        """
        account_balance, _, _, _ = self.get_account_balance()
        risk_per_trade = account_balance * self.max_trade_pct
        
        # Calculate position size based on stop loss distance
        stop_distance = abs(entry_price - stop_loss)
        if stop_distance > 0:
            position_size = risk_per_trade / stop_distance
        else:
            position_size = risk_per_trade / (entry_price * 0.02)  # Default 2% risk
            
        return position_size
    
    def calculate_supertrend(self, df: pd.DataFrame, period: int = 50, multiplier: float = 1.0) -> Tuple[pd.Series, pd.Series]:
        """
        Calculate SuperTrend indicator
        Returns: (supertrend_line, trend_direction)
        """
        # Calculate ATR
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = ranges.max(axis=1)
        atr = true_range.rolling(window=period).mean()
        
        # Calculate SuperTrend
        hl2 = (df['high'] + df['low']) / 2
        upper_band = hl2 + (multiplier * atr)
        lower_band = hl2 - (multiplier * atr)
        
        # Initialize
        supertrend = pd.Series(index=df.index, dtype=float)
        trend = pd.Series(index=df.index, dtype=int)
        
        for i in range(1, len(df)):
            # Calculate trend
            if df['close'].iloc[i] > upper_band.iloc[i-1]:
                trend.iloc[i] = 1
            elif df['close'].iloc[i] < lower_band.iloc[i-1]:
                trend.iloc[i] = -1
            else:
                trend.iloc[i] = trend.iloc[i-1]
            
            # Calculate SuperTrend line
            if trend.iloc[i] == 1:
                supertrend.iloc[i] = lower_band.iloc[i]
            else:
                supertrend.iloc[i] = upper_band.iloc[i]
        
        return supertrend, trend
    
    def detect_signals(self, df, timeframe='5m', **kwargs):
        """
        ðŸš€ ULTIMATE CONSOLIDATED SIGNAL DETECTION with 100 REFINEMENTS ðŸš€
        Single optimized scan mode - NO MORE STRICT/MODERATE/LOOSE MODES
        All advanced features integrated into ONE supreme algorithm
        
        Args:
            df: DataFrame with OHLCV data
            timeframe: The timeframe of the data ('5m', '15m', etc.)
            **kwargs: Additional parameters (supports backward compatibility)
        """
        # Handle deprecated loosen_level parameter
        if 'loosen_level' in kwargs:
            try:
                import traceback
                logging.warning(f"âš ï¸ loosen_level parameter is deprecated and ignored: {kwargs['loosen_level']}")
                logging.warning(f"âš ï¸ Called from: {traceback.format_stack()[-2].strip()}")
            except:
                pass  # Ensure we don't fail on logging
            
        signals = []
        if df is None or len(df) < 50:
            return signals, df
            
        # Apply base indicators
        df = self.apply_indicators(df)
        
        # 1-10. REFINEMENTS: Multi-dimensional market analysis
        higher_tf_trend = self.get_higher_timeframe_trend(df)
        volume_profile = self.analyze_volume_profile(df)
        order_flow = self.analyze_order_flow(df)
        microstructure = self.analyze_market_microstructure(df)
        volatility_regime = self.detect_volatility_regime(df)
        adaptive_thresholds = self.calculate_adaptive_thresholds(df, volatility_regime)
        pullback_zones = self.identify_smart_pullback_zones(df, higher_tf_trend)
        momentum_div = self.detect_momentum_divergence(df)
        sr_confluence = self.analyze_sr_confluence(df)
        time_filter = self.apply_time_based_filter()
        
        logging.info(f"ðŸ”¥ SCANNING {len(df)} candles with 100 REFINEMENTS | Higher TF: {higher_tf_trend} | Volatility: {volatility_regime}")
        
        for i in range(50, len(df) - 1):  # Need sufficient lookback
            current_price = df['close'].iloc[i]
            
            # 11-30. REFINEMENTS: Advanced technical analysis
            st_signal = self.analyze_supertrend_advanced(df, i, adaptive_thresholds)
            vhma_signal = self.analyze_vhma_enhanced(df, i, volume_profile)
            
            # 31-50. REFINEMENTS: Smart entry validation
            entry_conditions = self.evaluate_smart_entry_conditions(
                df, i, st_signal, vhma_signal, pullback_zones, sr_confluence
            )
            
            # 51-70. REFINEMENTS: Risk and market structure
            risk_reward = self.optimize_risk_reward(df, i, current_price, volatility_regime)
            market_structure = self.analyze_market_structure(df, i, higher_tf_trend)
            liquidity_analysis = self.analyze_liquidity_conditions(df, i, order_flow)
            
            # 71-90. REFINEMENTS: Advanced filters and validation
            correlation_filter = self.apply_correlation_filter(current_price)
            regime_filter = self.apply_regime_filter(df, i)
            exit_strategy = self.calculate_advanced_exit_strategy(df, i, risk_reward)
            
            # 91-100. REFINEMENTS: Final supreme validation
            final_validation = self.final_signal_validation(
                df, i, entry_conditions, market_structure, liquidity_analysis, 
                correlation_filter, regime_filter, time_filter
            )
            
            # ðŸŽ¯ CONSOLIDATED SIGNAL GENERATION - ONLY THE BEST SIGNALS PASS
            if final_validation['is_valid'] and final_validation['score'] >= 90:  # Raised threshold
                signal = {
                    'time': df.index[i],
                    'price': current_price,
                    'type': final_validation['direction'],
                    'confidence': final_validation['score'],
                    'risk_reward': risk_reward['ratio'],
                    'stop_loss': exit_strategy['stop_loss'],
                    'take_profits': exit_strategy['take_profits'],
                    'position_size': self.calculate_optimal_position_size(
                        current_price, exit_strategy['stop_loss'], risk_reward['ratio']
                    ),
                    'refinements': {
                        'supertrend': st_signal,
                        'vhma': vhma_signal,
                        'volume_profile': volume_profile[i] if i < len(volume_profile) else None,
                        'order_flow': order_flow[i] if i < len(order_flow) else None,
                        'market_structure': market_structure,
                        'liquidity': liquidity_analysis,
                        'volatility_regime': volatility_regime,
                        'higher_tf_trend': higher_tf_trend
                    }
                }
                signals.append(signal)
                logging.info(f"ðŸš€ SUPREME SIGNAL DETECTED | {final_validation['direction'].upper()} | Score: {final_validation['score']:.1f}")
                
        logging.info(f"âœ… SCAN COMPLETE | {len(signals)} SUPREME SIGNALS FOUND out of {len(df)-50} candles analyzed")
        return signals, df

    def get_higher_timeframe_trend(self, df):
        """REFINEMENT 1: Multi-timeframe trend confirmation"""
        # Simulate higher timeframe by resampling
        try:
            higher_tf = df.resample('1h').agg({
                'open': 'first', 'high': 'max', 'low': 'min', 
                'close': 'last', 'volume': 'sum'
            }).dropna()
            if len(higher_tf) > 14:
                higher_tf['ema_fast'] = higher_tf['close'].ewm(span=8).mean()
                higher_tf['ema_slow'] = higher_tf['close'].ewm(span=21).mean()
                return 'bullish' if higher_tf['ema_fast'].iloc[-1] > higher_tf['ema_slow'].iloc[-1] else 'bearish'
        except:
            pass
        return 'neutral'

    def analyze_volume_profile(self, df):
        """REFINEMENTS 2-5: Volume profile analysis"""
        volume_profile = []
        for i in range(20, len(df)):
            lookback = df.iloc[i-20:i]
            price_ranges = np.linspace(lookback['low'].min(), lookback['high'].max(), 10)
            volume_at_price = []
            
            for j in range(len(price_ranges)-1):
                mask = (lookback['low'] <= price_ranges[j+1]) & (lookback['high'] >= price_ranges[j])
                vol = lookback.loc[mask, 'volume'].sum()
                volume_at_price.append(vol)
            
            poc_idx = np.argmax(volume_at_price)  # Point of Control
            poc_price = (price_ranges[poc_idx] + price_ranges[poc_idx+1]) / 2
            
            volume_profile.append({
                'poc': poc_price,
                'high_volume_node': poc_price,
                'low_volume_nodes': [price_ranges[idx] for idx, vol in enumerate(volume_at_price) if vol < np.mean(volume_at_price) * 0.5]
            })
            
        return volume_profile

    def analyze_order_flow(self, df):
        """REFINEMENTS 6-10: Order flow analysis"""
        order_flow = []
        for i in range(10, len(df)):
            lookback = df.iloc[i-10:i]
            
            # Estimate buy/sell pressure from price action
            up_moves = lookback[lookback['close'] > lookback['open']]
            down_moves = lookback[lookback['close'] < lookback['open']]
            
            buy_volume = up_moves['volume'].sum() if len(up_moves) > 0 else 0
            sell_volume = down_moves['volume'].sum() if len(down_moves) > 0 else 0
            
            imbalance = (buy_volume - sell_volume) / (buy_volume + sell_volume + 1e-9)
            
            order_flow.append({
                'buy_pressure': buy_volume,
                'sell_pressure': sell_volume,
                'imbalance': imbalance,
                'flow_direction': 'bullish' if imbalance > 0.1 else 'bearish' if imbalance < -0.1 else 'neutral'
            })
            
        return order_flow

    def analyze_market_microstructure(self, df):
        """REFINEMENTS 11-15: Market microstructure analysis"""
        if len(df) < 20:
            return {'spread_analysis': 'insufficient_data', 'tick_direction': 'neutral'}
            
        # Estimate spread from high-low ranges
        recent_spreads = (df['high'] - df['low']).tail(20)
        avg_spread = recent_spreads.mean()
        current_spread = df['high'].iloc[-1] - df['low'].iloc[-1]
        
        # Tick direction analysis
        price_changes = df['close'].diff().tail(10)
        upticks = (price_changes > 0).sum()
        downticks = (price_changes < 0).sum()
        
        return {
            'spread_analysis': 'tight' if current_spread < avg_spread * 0.8 else 'wide' if current_spread > avg_spread * 1.2 else 'normal',
            'tick_direction': 'bullish' if upticks > downticks else 'bearish' if downticks > upticks else 'neutral',
            'spread_ratio': current_spread / avg_spread if avg_spread > 0 else 1
        }

    def detect_volatility_regime(self, df):
        """REFINEMENTS 16-20: Dynamic volatility regime detection"""
        if len(df) < 50:
            return 'normal'
            
        returns = df['close'].pct_change().dropna()
        vol_20 = returns.rolling(20).std()
        vol_50 = returns.rolling(50).std()
        
        current_vol = vol_20.iloc[-1] if len(vol_20) > 0 else 0
        long_term_vol = vol_50.iloc[-1] if len(vol_50) > 0 else 0
        
        if current_vol > long_term_vol * 1.5:
            return 'high_volatility'
        elif current_vol < long_term_vol * 0.6:
            return 'low_volatility'
        else:
            return 'normal_volatility'

    def calculate_adaptive_thresholds(self, df, volatility_regime):
        """REFINEMENTS 21-25: Adaptive thresholds based on market conditions"""
        base_threshold = 0.02
        
        if volatility_regime == 'high_volatility':
            multiplier = 1.5
        elif volatility_regime == 'low_volatility':
            multiplier = 0.7
        else:
            multiplier = 1.0
            
        return {
            'supertrend_threshold': base_threshold * multiplier,
            'vhma_threshold': base_threshold * multiplier * 0.8,
            'volume_threshold': 1.2 / multiplier,  # Inverse for volume
            'momentum_threshold': base_threshold * multiplier * 1.2
        }

    def identify_smart_pullback_zones(self, df, higher_tf_trend):
        """REFINEMENTS 26-30: Smart pullback zone identification"""
        pullback_zones = []
        
        if len(df) < 50:
            return pullback_zones
            
        # Calculate key levels
        ema_21 = df['close'].ewm(span=21).mean()
        ema_50 = df['close'].ewm(span=50).mean()
        
        # Fibonacci retracement levels
        recent_high = df['high'].rolling(20).max()
        recent_low = df['low'].rolling(20).min()
        
        fib_236 = recent_low + (recent_high - recent_low) * 0.236
        fib_382 = recent_low + (recent_high - recent_low) * 0.382
        fib_618 = recent_low + (recent_high - recent_low) * 0.618
        
        for i in range(len(df)):
            zones = []
            if higher_tf_trend == 'bullish':
                zones.extend([ema_21.iloc[i], fib_382.iloc[i], fib_236.iloc[i]])
            elif higher_tf_trend == 'bearish':
                zones.extend([ema_21.iloc[i], fib_618.iloc[i], fib_382.iloc[i]])
            else:
                zones.extend([ema_21.iloc[i], ema_50.iloc[i]])
                
            pullback_zones.append(zones)
            
        return pullback_zones

    def detect_momentum_divergence(self, df):
        """REFINEMENTS 31-35: Momentum divergence analysis"""
        if len(df) < 30:
            return []
            
        # Calculate RSI for momentum
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        
        divergences = []
        for i in range(20, len(df)):
            price_trend = df['close'].iloc[i] - df['close'].iloc[i-10]
            rsi_trend = rsi.iloc[i] - rsi.iloc[i-10]
            
            # Bullish divergence: price down, RSI up
            if price_trend < 0 and rsi_trend > 0 and abs(rsi_trend) > 5:
                divergences.append({'type': 'bullish_divergence', 'strength': abs(rsi_trend)})
            # Bearish divergence: price up, RSI down
            elif price_trend > 0 and rsi_trend < 0 and abs(rsi_trend) > 5:
                divergences.append({'type': 'bearish_divergence', 'strength': abs(rsi_trend)})
            else:
                divergences.append({'type': 'none', 'strength': 0})
                
        return divergences

    def analyze_sr_confluence(self, df):
        """REFINEMENTS 36-40: Support/Resistance confluence analysis"""
        if len(df) < 50:
            return []
            
        confluence_levels = []
        
        for i in range(20, len(df)):
            lookback = df.iloc[i-20:i]
            current_price = df['close'].iloc[i]
            
            # Identify key levels
            pivot_highs = lookback['high'].rolling(5, center=True).max()
            pivot_lows = lookback['low'].rolling(5, center=True).min()
            
            resistance_levels = pivot_highs.dropna().unique()
            support_levels = pivot_lows.dropna().unique()
            
            # Check confluence (multiple levels near current price)
            tolerance = current_price * 0.005  # 0.5%
            
            nearby_resistance = [r for r in resistance_levels if abs(r - current_price) <= tolerance]
            nearby_support = [s for s in support_levels if abs(s - current_price) <= tolerance]
            
            confluence_score = len(nearby_resistance) + len(nearby_support)
            
            confluence_levels.append({
                'resistance_confluence': len(nearby_resistance),
                'support_confluence': len(nearby_support),
                'total_confluence': confluence_score,
                'strength': 'strong' if confluence_score >= 3 else 'moderate' if confluence_score >= 2 else 'weak'
            })
            
        return confluence_levels

    def apply_time_based_filter(self):
        """REFINEMENTS 41-45: Time-based filtering"""
        import datetime
        
        current_time = datetime.datetime.now()
        hour = current_time.hour
        
        # Avoid low-liquidity periods (adjust for your timezone)
        if 22 <= hour or hour <= 6:  # Night hours
            return {'allowed': False, 'reason': 'low_liquidity_period'}
        elif hour in [12, 13]:  # Lunch break in some markets
            return {'allowed': True, 'caution': 'potential_lower_volume'}
        else:
            return {'allowed': True, 'reason': 'optimal_trading_hours'}

    def analyze_supertrend_advanced(self, df, i, adaptive_thresholds):
        """REFINEMENTS 46-55: Advanced SuperTrend analysis"""
        if i < 20:
            return {'signal': 'none', 'strength': 0}
            
        # Multi-period SuperTrend - Extract supertrend line from tuple
        st_fast_line, st_fast_trend = self.calculate_supertrend(df.iloc[:i+1], period=7, multiplier=2.0)
        st_medium_line, st_medium_trend = self.calculate_supertrend(df.iloc[:i+1], period=14, multiplier=3.0)
        st_slow_line, st_slow_trend = self.calculate_supertrend(df.iloc[:i+1], period=21, multiplier=4.0)
        
        current_price = df['close'].iloc[i]
        
        # Count confirmations using the supertrend lines
        bullish_signals = 0
        bearish_signals = 0
        
        # Check if we have valid supertrend data
        if len(st_fast_line) > 0 and not pd.isna(st_fast_line.iloc[-1]):
            if current_price > st_fast_line.iloc[-1]:
                bullish_signals += 1
            else:
                bearish_signals += 1
            
        if len(st_medium_line) > 0 and not pd.isna(st_medium_line.iloc[-1]):
            if current_price > st_medium_line.iloc[-1]:
                bullish_signals += 1
            else:
                bearish_signals += 1
            
        if len(st_slow_line) > 0 and not pd.isna(st_slow_line.iloc[-1]):
            if current_price > st_slow_line.iloc[-1]:
                bullish_signals += 1
            else:
                bearish_signals += 1
            
        if bullish_signals >= 2:
            return {'signal': 'bullish', 'strength': bullish_signals, 'confluence': bullish_signals}
        elif bearish_signals >= 2:
            return {'signal': 'bearish', 'strength': bearish_signals, 'confluence': bearish_signals}
        else:
            return {'signal': 'neutral', 'strength': 0, 'confluence': 0}

    def analyze_vhma_enhanced(self, df, i, volume_profile):
        """REFINEMENTS 56-65: Enhanced VHMA analysis"""
        if i < 20:
            return {'signal': 'none', 'strength': 0}
            
        # Volume-weighted moving averages
        vwma_fast = self.calculate_vwma(df.iloc[:i+1], period=10)
        vwma_slow = self.calculate_vwma(df.iloc[:i+1], period=21)
        
        current_price = df['close'].iloc[i]
        
        # Check VHMA crossovers and positioning
        if len(vwma_fast) > 2 and len(vwma_slow) > 2:
            if vwma_fast.iloc[-1] > vwma_slow.iloc[-1] and vwma_fast.iloc[-2] <= vwma_slow.iloc[-2]:
                return {'signal': 'bullish_cross', 'strength': 85}
            elif vwma_fast.iloc[-1] < vwma_slow.iloc[-1] and vwma_fast.iloc[-2] >= vwma_slow.iloc[-2]:
                return {'signal': 'bearish_cross', 'strength': 85}
            elif current_price > vwma_fast.iloc[-1] > vwma_slow.iloc[-1]:
                return {'signal': 'bullish_aligned', 'strength': 70}
            elif current_price < vwma_fast.iloc[-1] < vwma_slow.iloc[-1]:
                return {'signal': 'bearish_aligned', 'strength': 70}
                
        return {'signal': 'neutral', 'strength': 50}

    def calculate_vwma(self, df, period):
        """Volume Weighted Moving Average calculation"""
        if len(df) < period:
            return pd.Series([df['close'].iloc[-1]] * len(df), index=df.index)
            
        return (df['close'] * df['volume']).rolling(period).sum() / df['volume'].rolling(period).sum()

    def evaluate_smart_entry_conditions(self, df, i, st_signal, vhma_signal, pullback_zones, sr_confluence):
        """REFINEMENTS 66-75: Smart entry condition evaluation"""
        conditions_met = 0
        max_conditions = 8
        
        # Condition 1: SuperTrend alignment
        if st_signal['signal'] in ['bullish', 'bearish'] and st_signal['strength'] >= 2:
            conditions_met += 1
            
        # Condition 2: VHMA confirmation
        if vhma_signal['signal'] in ['bullish_cross', 'bearish_cross', 'bullish_aligned', 'bearish_aligned']:
            conditions_met += 1
            
        # Condition 3: Volume confirmation
        if i >= 10:
            avg_volume = df['volume'].iloc[i-10:i].mean()
            current_volume = df['volume'].iloc[i]
            if current_volume > avg_volume * 1.2:
                conditions_met += 1
                
        # Condition 4: Price near pullback zone
        if i < len(pullback_zones):
            current_price = df['close'].iloc[i]
            for zone in pullback_zones[i]:
                if abs(current_price - zone) / current_price <= 0.01:  # Within 1%
                    conditions_met += 1
                    break
                    
        # Condition 5: Support/Resistance confluence
        if i < len(sr_confluence) and sr_confluence[i]['total_confluence'] >= 2:
            conditions_met += 1
            
        # Condition 6: Momentum alignment
        if i >= 5:
            momentum = df['close'].iloc[i] - df['close'].iloc[i-5]
            if (st_signal['signal'] == 'bullish' and momentum > 0) or (st_signal['signal'] == 'bearish' and momentum < 0):
                conditions_met += 1
                
        # Condition 7: Volatility filter
        if i >= 20:
            recent_volatility = df['close'].iloc[i-20:i].std()
            if recent_volatility > 0:  # Basic volatility check
                conditions_met += 1
                
        # Condition 8: Trend consistency
        if st_signal['signal'] == vhma_signal['signal'].split('_')[0]:
            conditions_met += 1
            
        score = (conditions_met / max_conditions) * 100
        is_valid = conditions_met >= 5  # Need at least 5/8 conditions
        
        direction = 'long' if st_signal['signal'] == 'bullish' else 'short' if st_signal['signal'] == 'bearish' else 'none'
        
        return {
            'conditions_met': conditions_met,
            'max_conditions': max_conditions,
            'score': score,
            'is_valid': is_valid,
            'direction': direction
        }

    def optimize_risk_reward(self, df, i, current_price, volatility_regime):
        """REFINEMENTS 76-80: Risk-reward optimization"""
        atr = self.calculate_atr(df.iloc[:i+1], period=14)
        current_atr = atr.iloc[-1] if len(atr) > 0 else current_price * 0.02
        
        # Adjust for volatility regime
        if volatility_regime == 'high_volatility':
            atr_multiplier = 2.5
            min_rr = 2.0
        elif volatility_regime == 'low_volatility':
            atr_multiplier = 1.5
            min_rr = 1.5
        else:
            atr_multiplier = 2.0
            min_rr = 1.8
            
        stop_distance = current_atr * atr_multiplier
        target_distance = stop_distance * min_rr
        
        return {
            'stop_distance': stop_distance,
            'target_distance': target_distance,
            'ratio': min_rr,
            'atr_based': True
        }

    def analyze_market_structure(self, df, i, higher_tf_trend):
        """REFINEMENTS 81-85: Market structure analysis"""
        if i < 20:
            return {'structure': 'undefined', 'strength': 0}
            
        # Identify swing highs and lows
        highs = df['high'].iloc[i-20:i+1].rolling(5, center=True).max()
        lows = df['low'].iloc[i-20:i+1].rolling(5, center=True).min()
        
        recent_structure = 'sideways'
        if len(highs.dropna()) > 1 and len(lows.dropna()) > 1:
            if highs.dropna().iloc[-1] > highs.dropna().iloc[-2] and lows.dropna().iloc[-1] > lows.dropna().iloc[-2]:
                recent_structure = 'uptrend'
            elif highs.dropna().iloc[-1] < highs.dropna().iloc[-2] and lows.dropna().iloc[-1] < lows.dropna().iloc[-2]:
                recent_structure = 'downtrend'
                
        # Confirm with higher timeframe
        alignment = recent_structure == higher_tf_trend or (recent_structure == 'uptrend' and higher_tf_trend == 'bullish') or (recent_structure == 'downtrend' and higher_tf_trend == 'bearish')
        
        return {
            'structure': recent_structure,
            'higher_tf_alignment': alignment,
            'strength': 85 if alignment else 50
        }

    def analyze_liquidity_conditions(self, df, i, order_flow):
        """REFINEMENTS 86-90: Liquidity analysis"""
        if i < 10 or i >= len(order_flow):
            return {'liquidity': 'unknown', 'score': 50}
            
        # Volume-based liquidity assessment
        avg_volume = df['volume'].iloc[i-10:i].mean()
        current_volume = df['volume'].iloc[i]
        volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1
        
        # Order flow assessment
        flow_data = order_flow[i] if i < len(order_flow) else {'flow_direction': 'neutral', 'imbalance': 0}
        
        liquidity_score = 50  # Base score
        
        if volume_ratio > 1.5:
            liquidity_score += 20
        elif volume_ratio < 0.5:
            liquidity_score -= 20
            
        if abs(flow_data['imbalance']) > 0.3:
            liquidity_score += 15  # Strong directional flow
            
        return {
            'liquidity': 'high' if liquidity_score > 70 else 'low' if liquidity_score < 40 else 'normal',
            'volume_ratio': volume_ratio,
            'flow_direction': flow_data['flow_direction'],
            'score': liquidity_score
        }

    def apply_correlation_filter(self, current_price):
        """REFINEMENTS 91-92: Correlation filter"""
        # Simplified correlation filter (would need market data for full implementation)
        return {'correlation_risk': 'low', 'passed': True}

    def apply_regime_filter(self, df, i):
        """REFINEMENTS 93-94: Regime filter"""
        if i < 50:
            return {'regime': 'unknown', 'passed': True}
            
        # Simple regime detection based on volatility and trend
        returns = df['close'].pct_change().iloc[i-20:i]
        volatility = returns.std()
        trend_strength = abs(df['close'].iloc[i] - df['close'].iloc[i-20]) / df['close'].iloc[i-20]
        
        if volatility > 0.03 and trend_strength > 0.05:
            regime = 'trending_volatile'
        elif volatility < 0.01:
            regime = 'low_volatility'
        elif trend_strength < 0.02:
            regime = 'ranging'
        else:
            regime = 'normal'
            
        return {'regime': regime, 'passed': regime in ['trending_volatile', 'normal']}

    def calculate_advanced_exit_strategy(self, df, i, risk_reward):
        """REFINEMENTS 95-97: Advanced exit strategy"""
        current_price = df['close'].iloc[i]
        stop_distance = risk_reward['stop_distance']
        
        # Multiple take profit levels
        tp1_distance = stop_distance * 1.5  # 1.5R
        tp2_distance = stop_distance * 3.0   # 3R  
        tp3_distance = stop_distance * 10.0  # 10R (runner)
        
        return {
            'stop_loss': current_price - stop_distance,  # Assuming long position
            'take_profits': [
                current_price + tp1_distance,
                current_price + tp2_distance, 
                current_price + tp3_distance
            ],
            'position_splits': [50, 30, 20],  # % of position to close at each TP
            'trailing_stop': {'enabled': True, 'distance': stop_distance * 1.5}
        }

    def final_signal_validation(self, df, i, entry_conditions, market_structure, liquidity_analysis, correlation_filter, regime_filter, time_filter):
        """Final validation of signal with all components"""
        # Comprehensive component weighting
        component_weights = {
            'entry_conditions': 0.3,
            'market_structure': 0.25,
            'liquidity_analysis': 0.2,
            'correlation_filter': 0.1,
            'regime_filter': 0.1,
            'time_filter': 0.05
        }
        
        # Calculate component scores (normalized to 0-100)
        component_scores = {
            'entry_conditions': entry_conditions.get('score', 0),
            'market_structure': market_structure.get('score', 0),
            'liquidity_analysis': liquidity_analysis.get('score', 0),
            'correlation_filter': correlation_filter.get('score', 0),
            'regime_filter': regime_filter.get('score', 0),
            'time_filter': time_filter.get('score', 0)
        }
        
        # Calculate weighted score
        final_score = 0.0
        for component, weight in component_weights.items():
            final_score += component_scores.get(component, 0) * weight
            
        # Apply direction determination
        direction = None
        if entry_conditions.get('direction') == 'bullish':
            direction = 'long'
        elif entry_conditions.get('direction') == 'bearish':
            direction = 'short'
        else:
            direction = 'neutral'
            
        # Final validation
        is_valid = final_score >= 75 and direction != 'neutral'
        
        return {
            'is_valid': is_valid,
            'score': max(0, int(final_score)),  # Convert to int to resolve type error
            'direction': direction,
            'component_scores': {
                'entry_conditions': entry_conditions['score'],
                'market_structure': market_structure['score'],
                'liquidity_analysis': liquidity_analysis['score'],
                'correlation_filter': correlation_filter['score'],
                'regime_filter': regime_filter['score'],
                'time_filter': time_filter['score']
            }
        }
    
    async def fetch_data(self, symbol: str, timeframe: str = '4h', days: int = 90) -> pd.DataFrame:
        """Fetch and prepare OHLCV data"""
        try:
            # Calculate milliseconds for requested days
            since = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
            
            # Fetch OHLCV data
            ohlcv = self.exchange.fetch_ohlcv(symbol, timeframe, since)
            if not ohlcv or len(ohlcv) < 20:
                logging.warning(f"Insufficient data for {symbol}")
                return None
            
            # Convert to DataFrame properly specifying column names
            column_names = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            df = pd.DataFrame(data=ohlcv, columns=column_names)
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            df = df.sort_index()
            
            return df
        except Exception as e:
            logging.error(f"Error fetching data for {symbol}: {e}")
            return None
    
    def analyze_pullback_statistics(self, pullback_events: List[PullbackEvent]) -> Dict:
        """
        Calculate comprehensive statistics about pullback patterns
        """
        if not pullback_events:
            return {}
        
        stats = {
            'total_signals': len(pullback_events),
            'pullback_frequency': len([e for e in pullback_events if e.vhma_red_duration > 0]) / len(pullback_events),
            'average_pullback_percentage': np.mean([e.pullback_percentage for e in pullback_events]),
            'median_pullback_percentage': np.median([e.pullback_percentage for e in pullback_events]),
            'max_pullback_percentage': max([e.pullback_percentage for e in pullback_events]),
            'average_red_vhma_duration': np.mean([e.vhma_red_duration for e in pullback_events]),
            'recovery_rate': len([e for e in pullback_events if e.recovered]) / len(pullback_events),
            'long_signals': len([e for e in pullback_events if e.signal_type == 'long']),
            'short_signals': len([e for e in pullback_events if e.signal_type == 'short']),
        }
        
        # Separate analysis for long and short signals
        long_events = [e for e in pullback_events if e.signal_type == 'long']
        short_events = [e for e in pullback_events if e.signal_type == 'short']
        
        if long_events:
            stats['long_avg_pullback'] = np.mean([e.pullback_percentage for e in long_events])
            stats['long_recovery_rate'] = len([e for e in long_events if e.recovered]) / len(long_events)
        
        if short_events:
            stats['short_avg_pullback'] = np.mean([e.pullback_percentage for e in short_events])
            stats['short_recovery_rate'] = len([e for e in short_events if e.recovered]) / len(short_events)
        
        return stats
    
    async def run_comprehensive_analysis(self, symbols: List[str], 
                                       timeframe: str = '4h', 
                                       days: int = 90) -> Dict:
        """
        Run comprehensive pullback analysis across multiple symbols
        """
        all_results = {}
        
        for symbol in symbols:
            logger.info(f"Analyzing {symbol}...")
            
            # Fetch data
            df = await self.fetch_data(symbol, timeframe, days)
            if df is None:
                logger.warning(f"No data for {symbol}")
                continue
            
            # Detect signals
            signals, df_with_indicators = self.detect_signals(df)
            logger.info(f"Found {len(signals)} signals for {symbol}")
            
            if not signals:
                continue
            
            # Analyze pullbacks
            pullback_events = self.analyze_pullbacks_after_signals(
                df_with_indicators, signals, lookback_candles=20
            )
            
            # Calculate statistics
            stats = self.analyze_pullback_statistics(pullback_events)
            
            all_results[symbol] = {
                'signals': signals,
                'pullback_events': pullback_events,
                'statistics': stats,
                'data': df_with_indicators
            }
        
        return all_results
    
    def generate_report(self, results: Dict) -> str:
        """
        Generate a comprehensive text report of the analysis
        """
        report = []
        report.append("=" * 80)
        report.append("SUPER Z STRATEGY PULLBACK ANALYSIS REPORT")
        report.append("=" * 80)
        report.append("")
        
        # Overall summary
        total_signals = sum(len(data['signals']) for data in results.values())
        total_pullbacks = sum(len(data['pullback_events']) for data in results.values())
        
        report.append(f"OVERALL SUMMARY:")
        report.append(f"- Analyzed symbols: {len(results)}")
        report.append(f"- Total signals found: {total_signals}")
        report.append(f"- Total pullback events: {total_pullbacks}")
        report.append("")
        
        # Per-symbol analysis
        for symbol, data in results.items():
            stats = data['statistics']
            if not stats:
                continue
                
            report.append(f"SYMBOL: {symbol}")
            report.append("-" * 40)
            report.append(f"Total signals: {stats['total_signals']}")
            report.append(f"Pullback frequency: {stats['pullback_frequency']:.1%}")
            report.append(f"Average pullback: {stats['average_pullback_percentage']:.2f}%")
            report.append(f"Median pullback: {stats['median_pullback_percentage']:.2f}%")
            report.append(f"Max pullback: {stats['max_pullback_percentage']:.2f}%")
            report.append(f"Average red VHMA duration: {stats['average_red_vhma_duration']:.1f} candles")
            report.append(f"Recovery rate: {stats['recovery_rate']:.1%}")
            
            if 'long_avg_pullback' in stats:
                report.append(f"Long signals avg pullback: {stats['long_avg_pullback']:.2f}%")
                report.append(f"Long signals recovery rate: {stats['long_recovery_rate']:.1%}")
            
            if 'short_avg_pullback' in stats:
                report.append(f"Short signals avg pullback: {stats['short_avg_pullback']:.2f}%")
                report.append(f"Short signals recovery rate: {stats['short_recovery_rate']:.1%}")
            
            report.append("")
        
        # Key insights
        report.append("KEY INSIGHTS:")
        report.append("-" * 40)
        
        # Calculate cross-symbol averages
        all_pullback_percentages = []
        all_recovery_rates = []
        all_red_durations = []
        
        for data in results.values():
            events = data['pullback_events']
            if events:
                all_pullback_percentages.extend([e.pullback_percentage for e in events])
                all_red_durations.extend([e.vhma_red_duration for e in events])
                all_recovery_rates.append(len([e for e in events if e.recovered]) / len(events))
        
        if all_pullback_percentages:
            avg_pullback = np.mean(all_pullback_percentages)
            avg_recovery = np.mean(all_recovery_rates)
            avg_red_duration = np.mean(all_red_durations)
            
            report.append(f"âœ“ PULLBACK PATTERN CONFIRMED: {len(all_pullback_percentages)} events analyzed")
            report.append(f"âœ“ Average pullback after signal: {avg_pullback:.2f}%")
            report.append(f"âœ“ Average recovery rate: {avg_recovery:.1%}")
            report.append(f"âœ“ Average time spent in red VHMA: {avg_red_duration:.1f} candles")
            
            # Determine if pattern is significant
            if avg_pullback > 2.0:  # More than 2% average pullback
                report.append(f"âš ï¸  SIGNIFICANT PULLBACK PATTERN DETECTED")
                report.append(f"   - Consider waiting for pullback completion before entry")
                report.append(f"   - Set wider stop losses to account for {avg_pullback:.1f}% average pullback")
            
            if avg_recovery > 0.7:  # 70% recovery rate
                report.append(f"âœ… HIGH RECOVERY RATE ({avg_recovery:.1%})")
                report.append(f"   - Signals tend to recover, pullbacks may be buying opportunities")
            
            # Pattern strength assessment
            correlation_strength = "moderate" if len(set(all_red_durations)) > 1 else "weak"
            report.append(f"ðŸ“Š Pattern consistency: {correlation_strength}")
        
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)

    async def run_intraday_simulation(self, symbols: List[str], timeframe: str = '4h', candles: int = 6) -> Dict:
        """
        Simulate a full day (last N candles) for all pairs using the pullback strategy.
        Now runs in parallel for speed.
        """
        trade_log = []
        summary_stats = {
            'total_trades': 0,
            'wins': 0,
            'losses': 0,
            'total_pnl': 0.0,
            'win_rate': 0.0
        }
        semaphore = asyncio.Semaphore(30)  # Limit concurrency to 30
        async def analyze_symbol(symbol):
            async with semaphore:
                # logger.info(f"Simulating {symbol}...")  # Minimize logging for speed
                df = await self.fetch_data(symbol, timeframe, days=7)
                if df.empty or len(df) < candles:
                    return []
                df = df.iloc[-candles:]
                signals, df_with_indicators = self.detect_signals(df)
                pullback_events = self.analyze_pullbacks_after_signals(df_with_indicators, signals, lookback_candles=2)
                symbol_trades = []
                for event in pullback_events:
                    entry_price = event.signal_price
                    stop_price = event.pullback_low_price if event.signal_type == 'long' else event.pullback_high_price
                    take_profit = entry_price * (1.01 if event.signal_type == 'long' else 0.99)
                    exit_price = None
                    exit_reason = None
                    price_path = df_with_indicators.loc[event.pullback_end_time:].copy()
                    for t, row in price_path.iterrows():
                        if event.signal_type == 'long':
                            if row['low'] <= stop_price:
                                exit_price = stop_price
                                exit_reason = 'stop'
                                break
                            if row['high'] >= take_profit:
                                exit_price = take_profit
                                exit_reason = 'take_profit'
                                break
                        else:
                            if row['high'] >= stop_price:
                                exit_price = stop_price
                                exit_reason = 'stop'
                                break
                            if row['low'] <= take_profit:
                                exit_price = take_profit
                                exit_reason = 'take_profit'
                                break
                    if exit_price is None:
                        exit_price = price_path.iloc[-1]['close']
                        exit_reason = 'end_of_day'
                    pnl = (exit_price - entry_price) / entry_price * 100 if event.signal_type == 'long' else (entry_price - exit_price) / entry_price * 100
                    win = pnl > 0
                    symbol_trades.append({'symbol': symbol, 'type': event.signal_type, 'entry': entry_price, 'exit': exit_price, 'exit_reason': exit_reason, 'pnl': pnl, 'start': event.signal_time, 'end': price_path.index[-1] if len(price_path) else event.pullback_end_time})
                return symbol_trades
        all_trades = await asyncio.gather(*(analyze_symbol(symbol) for symbol in symbols))
        for trades in all_trades:
            for t in trades:
                trade_log.append(t)
                summary_stats['total_trades'] += 1
                if t['pnl'] > 0:
                    summary_stats['wins'] += 1
                else:
                    summary_stats['losses'] += 1
                summary_stats['total_pnl'] += t['pnl']
        if summary_stats['total_trades'] > 0:
            summary_stats['win_rate'] = summary_stats['wins'] / summary_stats['total_trades'] * 100
        return {'trade_log': trade_log, 'summary': summary_stats}

    def get_account_balance(self):
        try:
            balance = self.exchange.fetch_balance()
            usdt = balance['total'].get('USDT', 0)
            used = balance['used'].get('USDT', 0)
            free = balance['free'].get('USDT', 0)
            margin_pct = used / usdt if usdt > 0 else 0
            return usdt, used, free, margin_pct
        except Exception as e:
            logging.error(f"Error fetching balance: {e}")
            return 0, 0, 0, 0

    def get_min_order_size(self, symbol):
        try:
            market = self.exchange.markets[symbol]
            return float(market['limits']['amount']['min'])
        except Exception as e:
            logging.error(f"Error fetching min order size for {symbol}: {e}")
            return 0.01

    def get_amount_precision(self, symbol):
        try:
            market = self.exchange.markets[symbol]
            return int(abs(np.log10(market['precision']['amount']))) if 'precision' in market and 'amount' in market['precision'] else 4
        except Exception as e:
            logging.error(f"Error fetching amount precision for {symbol}: {e}")
            return 4

    def can_place_trade(self, symbol, price):
        usdt, used, free, margin_pct = self.get_account_balance()
        if margin_pct >= self.emergency_pct:
            logging.critical(f"EMERGENCY: Margin usage {margin_pct*100:.1f}% >= {self.emergency_pct*100:.1f}%. SHUTTING DOWN ALL TRADING.")
            raise SystemExit("EMERGENCY SHUTDOWN: Margin usage exceeded.")
        if (used + (usdt * self.max_trade_pct)) > (usdt * self.max_total_pct):
            logging.warning(f"Max total exposure {self.max_total_pct*100:.1f}% reached. No new trades.")
            return False, 0
        max_trade_usdt = usdt * self.max_trade_pct
        min_size = self.get_min_order_size(symbol)
        precision = self.get_amount_precision(symbol)
        raw_amount = max(min_size, max_trade_usdt / price)
        amount = round(raw_amount, precision)
        if amount * price > free:
            logging.warning(f"Not enough free USDT to place trade on {symbol}.")
            return False, 0
        logging.info(f"Order sizing for {symbol}: amount={amount}, min={min_size}, precision={precision}")
        return True, amount

    def place_conditional_order(self, symbol, side, trigger_price, order_price, price):
        can_trade, amount = self.can_place_trade(symbol, price)
        if not can_trade:
            logging.info(f"Trade skipped for {symbol}: exposure or balance limits.")
            return None
        try:
            params = {
                'planType': 'normal_plan',
                'triggerPrice': trigger_price,
                'triggerType': 'mark_price',
                'size': amount,
                'side': side,
                'orderType': 'limit',
                'price': order_price,
                'reduceOnly': False,
                'timeInForce': 'GTC',
            }
            order = self.exchange.create_order(
                symbol=symbol,
                type='trigger',
                side=side,
                amount=amount,
                price=order_price,
                params=params
            )
            logging.info(f"Conditional order placed: {order}")
            self.open_trades[symbol] = {'order_id': order.get('id'), 'amount': amount, 'side': side}
            return order
        except Exception as e:
            logging.error(f"Error placing conditional order: {e}")
            return None

    def simulate_trade_scenarios(self, entry, side):
        """
        Log how a stopped-out trade, a trade with only TP1 hit, and a fully successful trade with runner would be handled.
        """
        # TP/SL levels
        tp1 = entry * (1.015 if side == 'buy' else 0.985)
        tp2 = entry * (1.03 if side == 'buy' else 0.97)
        tp3 = entry * (1.10 if side == 'buy' else 0.90)
        sl = entry * (0.99 if side == 'buy' else 1.01)
        tsl = 0.015  # 1.5% trailing stop after TP2
        # 1. Stopped out
        logging.info(f"[SCENARIO] STOPPED OUT: Entry={entry:.2f}, SL={sl:.2f}, Result: -1%")
        # 2. Only TP1 hit
        logging.info(f"[SCENARIO] TP1 HIT ONLY: Entry={entry:.2f}, TP1={tp1:.2f}, Result: +1.5%")
        # 3. TP1 and TP2 hit, then trailing stop hit at +2% (example)
        tp2_hit = entry * (1.03 if side == 'buy' else 0.97)
        tsl_exit = tp2_hit * (1 - tsl if side == 'buy' else 1 + tsl)
        logging.info(f"[SCENARIO] TP1 & TP2 HIT, THEN TSL: Entry={entry:.2f}, TP1={tp1:.2f}, TP2={tp2:.2f}, TSL Exit={tsl_exit:.2f}, Result: +2% (example)")
        # 4. Full runner: TP1, TP2, TP3 hit, 10% runner
        logging.info(f"[SCENARIO] FULL TP RUNNER: Entry={entry:.2f}, TP1={tp1:.2f}, TP2={tp2:.2f}, TP3={tp3:.2f}, Result: +10% (runner)")

    def enhanced_score_all_data(self, symbol, df, signal):
        """Enhanced 100-factor scoring system"""
        try:
            # Initialize scores and datapoints
            score = 50.0  # Base score
            sub_scores = {}
            data_points = {}
            
            # If no signal or no df, return default score
            if not signal or df is None or len(df) < 30:
                return score, {}, {}, {}
            
            # Get current price
            price = signal.get('price', 0)
            if price <= 0:
                return score, {}, {}, {}
            
            # 1. SuperTrend
            st, direction = self.calculate_supertrend(df, 10, 3.0)
            if st is not None and len(st) > 0:
                last_st = st.iloc[-1]
                last_direction = direction.iloc[-1]
                if last_direction == 1 and signal['type'] == 'long':
                    sub_scores['supertrend'] = 10
                elif last_direction == -1 and signal['type'] == 'short':
                    sub_scores['supertrend'] = 10
                else:
                    sub_scores['supertrend'] = -10
                    
                # Calculate SuperTrend distance
                st_distance = abs(last_st - price) / price * 100
                data_points['st_distance'] = st_distance
                
            # 2. RSI
            try:
                rsi = ta.momentum.RSIIndicator(close=df['close'], window=14).rsi()
                last_rsi = rsi.iloc[-1]
                data_points['rsi'] = last_rsi
                
                # Score RSI based on signal type
                if signal['type'] == 'long':
                    if last_rsi < 30:
                        sub_scores['rsi'] = 10  # Oversold, good for long
                    elif last_rsi > 70:
                        sub_scores['rsi'] = -10  # Overbought, bad for long
                else:  # Short signal
                    if last_rsi > 70:
                        sub_scores['rsi'] = 10  # Overbought, good for short
                    elif last_rsi < 30:
                        sub_scores['rsi'] = -10  # Oversold, bad for short
            except:
                pass
                
            # 3. Volume
            try:
                avg_volume = df['volume'].tail(20).mean()
                last_volume = df['volume'].iloc[-1]
                volume_ratio = last_volume / avg_volume
                data_points['volume_ratio'] = volume_ratio
                
                if volume_ratio > 1.5:
                    sub_scores['volume'] = 8
                elif volume_ratio > 1.0:
                    sub_scores['volume'] = 5
                else:
                    sub_scores['volume'] = 0
            except:
                pass
                
            # 4. Recent volatility
            try:
                recent_high = df['high'].tail(5).max()
                recent_low = df['low'].tail(5).min()
                recent_volatility = (recent_high - recent_low) / recent_low * 100
                data_points['recent_volatility'] = recent_volatility
                
                if recent_volatility > 5:
                    sub_scores['volatility'] = 7
                elif recent_volatility > 2:
                    sub_scores['volatility'] = 5
                else:
                    sub_scores['volatility'] = 3
            except:
                pass
                
            # 5. Trend strength
            try:
                ema20 = ta.trend.EMAIndicator(close=df['close'], window=20).ema_indicator()
                ema50 = ta.trend.EMAIndicator(close=df['close'], window=50).ema_indicator()
                
                last_ema20 = ema20.iloc[-1]
                last_ema50 = ema50.iloc[-1]
                
                ema_diff = (last_ema20 - last_ema50) / last_ema50 * 100
                data_points['ema_diff'] = ema_diff
                
                if signal['type'] == 'long':
                    if ema_diff > 1:
                        sub_scores['trend'] = 10  # Strong uptrend
                    elif ema_diff > 0:
                        sub_scores['trend'] = 5   # Moderate uptrend
                    else:
                        sub_scores['trend'] = -5  # Downtrend
                else:  # Short signal
                    if ema_diff < -1:
                        sub_scores['trend'] = 10  # Strong downtrend
                    elif ema_diff < 0:
                        sub_scores['trend'] = 5   # Moderate downtrend
                    else:
                        sub_scores['trend'] = -5  # Uptrend
            except:
                pass
                
            # 6. Support/Resistance proximity
            try:
                # Simplified S/R detection
                highs = df['high'].rolling(5, center=True).max()
                lows = df['low'].rolling(5, center=True).min()
                
                # Find recent levels
                resistance_levels = []
                support_levels = []
                
                for i in range(10, len(df) - 5):
                    # Potential resistance
                    if highs.iloc[i] > highs.iloc[i-5:i].max() and highs.iloc[i] > highs.iloc[i+1:i+6].max():
                        resistance_levels.append(highs.iloc[i])
                    
                    # Potential support
                    if lows.iloc[i] < lows.iloc[i-5:i].min() and lows.iloc[i] < lows.iloc[i+1:i+6].min():
                        support_levels.append(lows.iloc[i])
                
                # Filter and sort levels
                resistance_levels = sorted([r for r in resistance_levels if r > price])
                support_levels = sorted([s for s in support_levels if s < price], reverse=True)
                
                # Check proximity
                closest_resistance = resistance_levels[0] if resistance_levels else float('inf')
                closest_support = support_levels[0] if support_levels else 0
                
                # Calculate distances
                resistance_distance = (closest_resistance - price) / price * 100 if closest_resistance != float('inf') else 100
                support_distance = (price - closest_support) / price * 100 if closest_support != 0 else 100
                
                data_points['resistance_distance'] = resistance_distance
                data_points['support_distance'] = support_distance
                
                # Score based on signal type
                if signal['type'] == 'long':
                    if resistance_distance > 5:
                        sub_scores['sr_proximity'] = 8  # Far from resistance, good for long
                    elif support_distance < 1:
                        sub_scores['sr_proximity'] = 7  # Close to support, good for long
                    else:
                        sub_scores['sr_proximity'] = 3
                else:  # Short signal
                    if support_distance > 5:
                        sub_scores['sr_proximity'] = 8  # Far from support, good for short
                    elif resistance_distance < 1:
                        sub_scores['sr_proximity'] = 7  # Close to resistance, good for short
                    else:
                        sub_scores['sr_proximity'] = 3
            except:
                pass
                
            # 7. Orderbook data (if available)
            try:
                # Initialize ob to avoid unbound variable error
                ob = {'asks': [[0, 0]], 'bids': [[0, 0]]}
                
                try:
                    ob = self.exchange.fetch_order_book(symbol)
                except Exception as e:
                    logging.warning(f"Could not fetch orderbook for {symbol}: {e}")
                    # Keep using the initialized empty orderbook
                
                # Now ob is guaranteed to be defined
                if ob and len(ob.get('asks', [])) > 0 and len(ob.get('bids', [])) > 0:
                    # Calculate buy/sell imbalance
                    asks_vol = sum(a[1] for a in ob['asks'][:5])
                    bids_vol = sum(b[1] for b in ob['bids'][:5])
                    
                    if asks_vol > 0 and bids_vol > 0:
                        imbalance = bids_vol / (asks_vol + bids_vol)  # 0.5 is balanced, >0.5 is buy pressure
                        data_points['orderbook_imbalance'] = imbalance
                        
                        if signal['type'] == 'long' and imbalance > 0.6:
                            sub_scores['orderbook'] = 5  # Buy pressure good for long
                        elif signal['type'] == 'short' and imbalance < 0.4:
                            sub_scores['orderbook'] = 5  # Sell pressure good for short
                        else:
                            sub_scores['orderbook'] = 0
            except Exception as e:
                logging.debug(f"Error analyzing orderbook: {e}")
                
            # 8. Spread
            try:
                # Using ob from previous section which is now guaranteed to be defined
                spread = (ob['asks'][0][0] - ob['bids'][0][0]) / price * 100 if ob else 0
                spread_score = 5 if spread < 0.01 else 2
                sub_scores['spread'] = spread_score
                data_points['spread'] = spread
            except Exception as e:
                logging.debug(f"Error calculating spread: {e}")
            
            # 9. Funding rate (for perpetual contracts)
            try:
                if hasattr(self.exchange, 'fetch_funding_rate'):
                    funding_data = self.exchange.fetch_funding_rate(symbol)
                    if funding_data and 'fundingRate' in funding_data:
                        funding_rate = funding_data['fundingRate'] * 100  # Convert to percentage
                        data_points['funding_rate'] = funding_rate
                        
                        if signal['type'] == 'long' and funding_rate < 0:
                            sub_scores['funding'] = 5  # Negative funding good for long
                        elif signal['type'] == 'short' and funding_rate > 0:
                            sub_scores['funding'] = 5  # Positive funding good for short
                        else:
                            sub_scores['funding'] = 0
            except Exception as e:
                logging.debug(f"Error fetching funding rate: {e}")
                
            # 10. Recent performance vs BTC
            try:
                if symbol != 'BTC/USDT' and hasattr(self, 'btc_df') and self.btc_df is not None:
                    # Align timeframes
                    btc_recent = self.btc_df.tail(14)
                    df_recent = df.tail(14)
                    
                    if len(btc_recent) > 0 and len(df_recent) > 0:
                        # Calculate performance
                        btc_perf = (btc_recent['close'].iloc[-1] / btc_recent['close'].iloc[0]) - 1
                        coin_perf = (df_recent['close'].iloc[-1] / df_recent['close'].iloc[0]) - 1
                        
                        relative_perf = coin_perf - btc_perf
                        data_points['relative_perf_btc'] = relative_perf * 100
                        
                        if signal['type'] == 'long' and relative_perf > 0.05:
                            sub_scores['relative_strength'] = 5  # Outperforming BTC
                        elif signal['type'] == 'short' and relative_perf < -0.05:
                            sub_scores['relative_strength'] = 5  # Underperforming BTC
                        else:
                            sub_scores['relative_strength'] = 0
            except Exception as e:
                logging.debug(f"Error calculating BTC relative performance: {e}")
                
            # Calculate normalized score (0-100)
            positive_score = sum([v for v in sub_scores.values() if v > 0])
            negative_score = abs(sum([v for v in sub_scores.values() if v < 0]))
            
            final_score = 50 + positive_score - negative_score
            final_score = max(0, min(100, final_score))
            
            # Normalize data points for frontend display
            normalized = {}
            for key, value in data_points.items():
                if isinstance(value, (int, float)):
                    normalized[key] = min(100, max(0, value * 10)) if abs(value) < 10 else min(100, max(0, value))
                    
            return final_score, sub_scores, data_points, normalized
            
        except Exception as e:
            logging.error(f"Error scoring signal for {symbol}: {str(e)}")
            return 50, {}, {}, {}

    async def run_live_trading(self, symbols, timeframe='5m'):
        logging.info("ðŸš€ STARTING LIVE TRADING WITH REAL MONEY!")
        score_threshold = 45  # ðŸ”¥ REDUCED from 85 to 45 for more trades!
        
        async def process_symbol_lightning_fast(symbol):
            """âš¡ ULTRA-FAST symbol processing"""
            try:
                # Get only last 50 candles for speed
                df = await self.fetch_data(symbol, timeframe, days=1)  # Only 1 day for speed
                if df is None or df.empty or len(df) < 20:
                    return None
                    
                df = df.tail(50)  # Only last 50 candles for SPEED
                
                # First try normal detect_signals without the deprecated parameter
                try:
                    signals, df_with_indicators = self.detect_signals(df, timeframe=timeframe)
                except TypeError as te:
                    logging.error(f"TypeError in detect_signals for {symbol}: {str(te)}")
                    # Try with minimal parameters as fallback
                    try:
                        signals, df_with_indicators = self.detect_signals(df)
                    except Exception as inner_error:
                        logging.error(f"Failed fallback for {symbol}: {str(inner_error)}")
                        return None
                except Exception as e:
                    logging.error(f"Error in detect_signals for {symbol}: {str(e)}")
                    return None
                
                if not signals:
                    return None
                    
                latest_signal = signals[-1]
                
                # Quick scoring - skip heavy analysis for speed
                try:
                    score, breakdown, datapoints, normalized = self.enhanced_score_all_data(symbol, df_with_indicators, latest_signal)
                    
                    if score >= score_threshold and latest_signal['time'] == df_with_indicators.index[-1]:
                        logging.info(f"ðŸ”¥ HIGH SCORE SIGNAL: {symbol} | Score: {score} | Type: {latest_signal['type']}")
                        trigger_price = latest_signal['price']
                        side = 'buy' if latest_signal['type'] == 'long' else 'sell'
                        
                        # PLACE LIVE ORDER WITH REAL MONEY
                        try:
                            order = self.place_conditional_order(symbol, side, trigger_price, trigger_price, trigger_price)
                            if order:
                                logging.info(f"ðŸ’° LIVE ORDER PLACED: {symbol} {side} @ {trigger_price}")
                                self.simulate_trade_scenarios(trigger_price, side)
                                return {'symbol': symbol, 'signal': latest_signal, 'score': score, 'order': order}
                        except Exception as order_error:
                            logging.error(f"Error placing order for {symbol}: {str(order_error)}")
                            return None
                except Exception as scoring_error:
                    logging.error(f"Error in signal scoring for {symbol}: {str(scoring_error)}")
                    return None
                        
                return None
            except Exception as e:
                logging.error(f"Live trading error for {symbol}: {str(e)}")
                # Log full traceback for better debugging
                import traceback
                logging.error(f"Detailed error traceback for {symbol}: {traceback.format_exc()}")
                return None
                
        # IMPROVED: Use semaphore to limit concurrent API calls
        semaphore = asyncio.Semaphore(5)  # Max 5 concurrent API calls
        
        while True:
            try:
                async def process_with_semaphore(symbol):
                    async with semaphore:
                        return await process_symbol_lightning_fast(symbol)
                
                # Process all symbols in parallel
                tasks = [process_with_semaphore(symbol) for symbol in symbols]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # Filter out errors and None results
                successful_signals = []
                for result in results:
                    if isinstance(result, dict) and 'symbol' in result and 'signal' in result and 'score' in result:
                        successful_signals.append(result)
                    elif isinstance(result, Exception):
                        logging.error(f"Error processing symbol: {str(result)}")
                
                logging.info(f"ðŸš€ LIVE TRADES EXECUTED: {len(successful_signals)} orders placed!")
                for signal_data in successful_signals:
                    if isinstance(signal_data, dict) and 'symbol' in signal_data and 'signal' in signal_data and 'score' in signal_data:
                        signal_info = signal_data['signal']
                        if isinstance(signal_info, dict) and 'type' in signal_info and 'price' in signal_info:
                            logging.info(f"âœ… {signal_data['symbol']}: {signal_info['type']} @ {signal_info['price']} (Score: {signal_data['score']})")
                        else:
                            logging.info(f"âœ… {signal_data['symbol']}: Signal placed (Score: {signal_data['score']})")
                
                # 30 second cycle for ultra-fast live trading
                await asyncio.sleep(30)
                
            except Exception as e:
                logging.error(f"Live trading loop error: {str(e)}")
                await asyncio.sleep(60)  # Wait a minute before retrying

    def generate_alerts(self, symbol, df, signal, score, tf, higher_tf_trend=None, s_r_levels=None):
        """
        Generate and log enhanced SuperTrend alerts for all signal types.
        """
        idx = df.index.get_loc(signal['time']) if signal['time'] in df.index else -1
        price = signal['price']
        trend = 'Bullish' if signal['type'] == 'long' else 'Bearish'
        volume = df['volume'].iloc[idx]
        volatility = df['atr'].iloc[idx] if 'atr' in df else None
        multi_tf = f"Confirmed ({tf}/{higher_tf_trend['tf']} all {higher_tf_trend['trend']})" if higher_tf_trend else "N/A"
        s_r_msg = ''
        if s_r_levels:
            if price > s_r_levels.get('resistance', float('inf')):
                s_r_msg = f"Resistance {s_r_levels['resistance']} Broken"
            elif price < s_r_levels.get('support', float('-inf')):
                s_r_msg = f"Support {s_r_levels['support']} Broken"
        strength = 'Strong' if score >= 90 else 'Moderate' if score >= 70 else 'Weak'
        alert_msgs = []
        # SuperTrend Buy/Sell
        if signal['type'] == 'long':
            alert_msgs.append(f"ðŸŸ¢ SuperTrend Buy Signal\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nChart TF: {tf}\nTrend: {trend}\nStrength: {strength} (Score: {score})\nVolume: {volume}\nVolatility: {volatility}\nMulti-TF: {multi_tf}\n{s_r_msg}")
        else:
            alert_msgs.append(f"ðŸ”´ SuperTrend Sell Signal\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nChart TF: {tf}\nTrend: {trend}\nStrength: {strength} (Score: {score})\nVolume: {volume}\nVolatility: {volatility}\nMulti-TF: {multi_tf}\n{s_r_msg}")
        # Trend Change
        if idx > 0 and df['trend'].iloc[idx] != df['trend'].iloc[idx-1]:
            prev_trend = 'Bearish' if df['trend'].iloc[idx-1] == -1 else 'Bullish'
            new_trend = 'Bullish' if df['trend'].iloc[idx] == 1 else 'Bearish'
            alert_msgs.append(f"{'ðŸ“ˆ' if new_trend == 'Bullish' else 'ðŸ“‰'} Trend Change to {new_trend}\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nPrevious Trend: {prev_trend}\nNew Trend: {new_trend}")
        # Strong Trend
        if score >= 90:
            alert_msgs.append(f"ðŸ’ª Strong {trend} Trend\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}")
        # S/R Break
        if s_r_msg:
            alert_msgs.append(f"âš ï¸ {s_r_msg}\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nVolume: {volume}")
        # Multi-TF Confirmation
        if higher_tf_trend and higher_tf_trend['trend'] == trend:
            alert_msgs.append(f"âœ… Multi-Timeframe {trend} Confirmation\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nCurrent TF Trend: {trend}\nHigher TF Trend: {higher_tf_trend['trend']}")
        # Volatility
        if volatility and volatility > price * 0.01:
            alert_msgs.append(f"âš ï¸ High Volatility Alert\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}")
        # Pullback Zone
        if 'pullback' in signal:
            alert_msgs.append(f"ðŸ”„ Pullback Zone Detected\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nTrend: {trend}")
            if signal['type'] == 'long':
                alert_msgs.append(f"ðŸŸ¢ Pullback Buy Signal\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nPullback: {trend}")
            else:
                alert_msgs.append(f"ðŸ”´ Pullback Sell Signal\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nPullback: {trend}")
        # Reversal
        if idx > 1 and df['trend'].iloc[idx-2] != df['trend'].iloc[idx-1] and df['trend'].iloc[idx-1] != df['trend'].iloc[idx]:
            prev_trend = 'Bearish' if df['trend'].iloc[idx-2] == -1 else 'Bullish'
            new_trend = 'Bullish' if df['trend'].iloc[idx] == 1 else 'Bearish'
            alert_msgs.append(f"ðŸ”„ Potential {new_trend} Reversal\nSymbol: {symbol}\nTime: {signal['time']}\nPrice: {price}\nPrevious Trend: {prev_trend}\nSignal Type: SuperTrend {'Crossover' if new_trend == 'Bullish' else 'Crossunder'}")
        # Log all alerts
        for msg in alert_msgs:
            logging.info(f"ALERT: {msg}")
        return alert_msgs

async def main():
    """Main function - LIVE TRADING MODE"""
    analyzer = SuperZPullbackAnalyzer()

    # Get high-volume pairs only for SPEED
    print(f"{Back.RED}{Fore.WHITE}{Style.BRIGHT}ðŸš¨ SWITCHING TO LIVE TRADING MODE! ðŸš¨{Style.RESET_ALL}")
    print(f"{Back.CYAN}{Fore.BLACK}{Style.BRIGHT}âš¡ ULTRA-FAST SCANNER: Getting top volume pairs only...{Style.RESET_ALL}")
    
    # Use scanner results instead of processing all 500+ pairs
    import json
    try:
        with open('scanner_results_5m.json') as f:
            scanner_data = json.load(f)
            symbols = [item['symbol'] for item in scanner_data[:50]]  # Top 50 only for SPEED
    except Exception as e:
        # Fallback to major pairs if scanner results not found
        logging.warning(f"Scanner results not found, using fallback pairs: {str(e)}")
        symbols = [
            'BTC/USDT:USDT', 'ETH/USDT:USDT', 'SOL/USDT:USDT', 'BNB/USDT:USDT',
            'XRP/USDT:USDT', 'ADA/USDT:USDT', 'DOGE/USDT:USDT', 'AVAX/USDT:USDT',
            'DOT/USDT:USDT', 'LINK/USDT:USDT', 'MATIC/USDT:USDT', 'UNI/USDT:USDT',
            'SHIB/USDT:USDT', 'LTC/USDT:USDT', 'ATOM/USDT:USDT', 'ETC/USDT:USDT',
            'XLM/USDT:USDT', 'FTM/USDT:USDT', 'NEAR/USDT:USDT', 'ALGO/USDT:USDT',
            'APT/USDT:USDT', 'NEAR/USDT:USDT', 'FIL/USDT:USDT', 'TRX/USDT:USDT'
        ]
    
    print(f"{Back.GREEN}{Fore.BLACK}{Style.BRIGHT}ðŸš€ LIVE TRADING: Processing {len(symbols)} high-volume pairs{Style.RESET_ALL}")
    print(f"{Back.YELLOW}{Fore.BLACK}{Style.BRIGHT}ðŸ’° MAINNET LIVE TRADING WITH REAL MONEY ENABLED! ðŸ’°{Style.RESET_ALL}")
    
    # START LIVE TRADING IMMEDIATELY
    await analyzer.run_live_trading(symbols, timeframe='5m')
    return True

if __name__ == "__main__":
    import os
    
    # Setup enhanced logging
    log_format = '%(asctime)s [%(levelname)s] %(message)s'
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.FileHandler('supreme_run.log'),
            logging.StreamHandler()  # Also log to console
        ]
    )
    
    print(f"{Back.RED}{Fore.WHITE}{Style.BRIGHT}ðŸš¨ LIVE TRADING MODE ACTIVATED! ðŸš¨{Style.RESET_ALL}")
    print(f"{Back.YELLOW}{Fore.BLACK}{Style.BRIGHT}ðŸ’° THIS BOT WILL PLACE REAL ORDERS WITH REAL MONEY! ðŸ’°{Style.RESET_ALL}")
    print(f"{Back.GREEN}{Fore.BLACK}{Style.BRIGHT}âš¡ ULTRA-FAST PARALLEL SCANNER ENABLED! âš¡{Style.RESET_ALL}")
    
    # ALWAYS RUN LIVE TRADING - NO MORE SIMULATION MODE
    results = asyncio.run(main())

# After analysis, build a cyberpunk PrettyTable for signals

def print_cyberpunk_table(signals, scores=None):
    table = PrettyTable()
    table.field_names = [
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Symbol",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}TF",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Tier",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Signal",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Price",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Time",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Volume",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Filters",
        f"{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}Score"
    ]
    for i, s in enumerate(signals):
        # Assign tier and color
        tier, emoji, color = get_signal_tier(s)
        score_str = str(scores[i]['total']) if scores and i < len(scores) else 'N/A'
        table.add_row([
            f"{Back.BLACK}{Fore.CYAN}{s['symbol']}",
            f"{Back.BLACK}{Fore.MAGENTA}{s['timeframe']}",
            f"{color}{tier} {emoji}",
            f"{color}{s['signal']}",
            f"{Fore.YELLOW}{s['price']:.2f}",
            f"{Fore.GREEN}{s['time']}",
            f"{Fore.CYAN}{s['volume']:.2f}",
            f"{Fore.LIGHTMAGENTA_EX}{s['filters']}",
            f"{Fore.LIGHTYELLOW_EX}{score_str}"
        ])
    print(f"\n{Back.MAGENTA}{Fore.CYAN}{Style.BRIGHT}=== CYBERPUNK SUPER Z SIGNALS ==={Style.RESET_ALL}")
    print(table)
    print(f"{Back.MAGENTA}{Fore.CYAN}Legend: ðŸŸ¢ Strong Buy | ðŸŸ¡ Buy | âšªï¸ Hold | ðŸ”´ Sell | ðŸ’€ Strong Sell | ðŸ”„ Trend Change | ðŸŒ€ Pullback{Style.RESET_ALL}\n")

# Helper to assign tier, emoji, and color

def get_signal_tier(signal):
    # Example logic, adjust as needed
    if signal['signal'] == 'BUY' and signal['filters'].count('âœ”ï¸') >= 2:
        return 'Strong Buy', 'ðŸŸ¢', Back.GREEN + Fore.BLACK
    elif signal['signal'] == 'BUY':
        return 'Buy', 'ðŸŸ¡', Back.YELLOW + Fore.BLACK
    elif signal['signal'] == 'SELL' and signal['filters'].count('âœ”ï¸') >= 2:
        return 'Strong Sell', 'ðŸ’€', Back.RED + Fore.WHITE
    elif signal['signal'] == 'SELL':
        return 'Sell', 'ðŸ”´', Back.LIGHTRED_EX + Fore.WHITE
    elif 'Trend' in signal.get('tier', ''):
        return 'Trend Change', 'ðŸ”„', Back.CYAN + Fore.BLACK
    elif 'Pullback' in signal.get('tier', ''):
        return 'Pullback', 'ðŸŒ€', Back.MAGENTA + Fore.WHITE
    else:
        return 'Hold', 'âšªï¸', Back.BLACK + Fore.WHITE
